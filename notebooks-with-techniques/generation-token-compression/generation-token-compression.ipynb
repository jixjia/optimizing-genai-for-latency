{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation Token Compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Helper Functions and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "import json\n",
    "import time\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import copy\n",
    "import textwrap\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "def aoai_call(system_message,prompt,model):\n",
    "    client = AzureOpenAI(\n",
    "        api_version=os.getenv(\"API_VERSION\"),\n",
    "        azure_endpoint=os.getenv(\"AZURE_ENDPOINT\"),\n",
    "        api_key=os.getenv(\"API_KEY\")\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    e2e_time = end_time - start_time\n",
    "\n",
    "    result=json.loads(completion.model_dump_json(indent=2))\n",
    "    prompt_tokens=result[\"usage\"][\"prompt_tokens\"]\n",
    "    completion_tokens=result[\"usage\"][\"completion_tokens\"]\n",
    "    completion_text=result[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    return result,prompt_tokens,completion_tokens,completion_text,e2e_time\n",
    "\n",
    "model=os.getenv(\"MODELGPT432k\")\n",
    "\n",
    "# Read essay from a text file\n",
    "with open('sales_report.txt', 'r') as f:\n",
    "    sales_report = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case: Summarising a report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A: Naive summarisation, using the model's default verbosity\n",
    "\n",
    "**Time taken: 20 seconds**\n",
    "\n",
    "The model has a natural amount of verbosity- that is, the amount it chooses to say. Certain models will give long explanations to questions, other models may tend to give a more succinct answer. The total time taken for the model to finish is largely impacted by this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Tokens: 1554\n",
      "Completion Tokens: 277\n",
      "Total cost: $0.1265\n",
      "Time taken: 20.11 seconds\n"
     ]
    }
   ],
   "source": [
    "system_message=\"\"\"\n",
    "You are a helpful AI assistant.\n",
    "\"\"\"\n",
    "prompt=f\"\"\"\n",
    "Document to summarise:\n",
    "{sales_report}\n",
    "Summarise this document. Include the type of game, the sales performance by region, the performance of the launch, and feedback about the launch.\n",
    "\"\"\"\n",
    "\n",
    "result,prompt_tokens,completion_tokens,completion_text,e2e_time=aoai_call(system_message,prompt,model)\n",
    "print(f\"Prompt Tokens: {prompt_tokens}\")\n",
    "print(f\"Completion Tokens: {completion_tokens}\")\n",
    "print(f\"Time taken: {e2e_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The document discusses the global launch of a flagship real-time strategy (RTS) video game with an immersive gameplay, strategic planning, dynamic environments and characters. The game's launch exceeded expectations, particularly in the North American markets where the game sold 1.5 million units against the projected one million units. This success was mirrored in its global sales, especially in the European and Asian markets, which sold 1.8 and 2.0 million units respectively. There was promising growth in the Latin American and African markets, despite lower sales numbers (0.5 and 0.3 million units respectively).\\n\\nUser feedback overall was a mixture of praise and critique. The game's mechanics and strategic elements received commendation, but the micro-transaction system, which involves the use of real money to buy in-game currency and expedite progress, was criticised for making the game too expensive and providing an unfair advantage to players who spend more.\\n\\nThe game's impressive sales figures underscore its appeal and quality, but user feedback points to an urgent need to improve the micro-transaction system. The company's future plan is to re-evaluate this system, making it transparent and fair while not disadvantaging those who choose not to spend extra. Additionally, they plan to alter their marketing strategies to better penetrate the less successful markets. Despite criticisms, the company is confident of continued success with these improvements.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B: Summarisation with a focus on conciseness\n",
    "\n",
    "**Time taken: 8.5 seconds**\n",
    "\n",
    "By simply asking the model to be more succinct, the LLM spends less time generating tokens, making the overall repsonse much faster.\n",
    "\n",
    "Of course, this may mean the answer is less complete, or doesn't fully meet the user's expectations. For backend processes, such as explaining the reason for a decision, this is often acceptable. For customer facing applications, this may also be ok, but testing is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Tokens: 1568\n",
      "Completion Tokens: 135\n",
      "Total cost: $0.1103\n",
      "Time taken: 8.49 seconds\n"
     ]
    }
   ],
   "source": [
    "system_message=\"\"\"\n",
    "You are a helpful AI assistant.\n",
    "\"\"\"\n",
    "prompt=f\"\"\"\n",
    "Document to summarise:\n",
    "{sales_report}\n",
    "Summarise this document. Include the type of game, the sales performance by region, the performance of the launch, and feedback about the launch. Be as succint as possible, using as few words as possible.\n",
    "\"\"\"\n",
    "\n",
    "result,prompt_tokens,completion_tokens,completion_text,e2e_time=aoai_call(system_message,prompt,model)\n",
    "print(f\"Prompt Tokens: {prompt_tokens}\")\n",
    "print(f\"Completion Tokens: {completion_tokens}\")\n",
    "print(f\"Time taken: {e2e_time:.2f} seconds\")\n",
    "print(completion_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C: Few shot prompting\n",
    "\n",
    "**Time taken: 8.2 seconds**\n",
    "\n",
    "The best approach is to use few shot prompting to help guide the model, to better optimise the balance between succinctness and completeness. This also has the advantage of providing a structured output, which will be consistent across the application (for example, every report being summarised will now be in the same format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Tokens: 2004\n",
      "Completion Tokens: 94\n",
      "Total cost: $0.1315\n",
      "Time taken: 8.20 seconds\n"
     ]
    }
   ],
   "source": [
    "system_message=\"\"\"\n",
    "You are a helpful AI assistant.\n",
    "\"\"\"\n",
    "prompt=f\"\"\"\n",
    "\n",
    "\n",
    "You must use the below structure for your summary.\n",
    "START_EXAMPLE:\n",
    "Document:\n",
    "Product Briefing Document\n",
    "I. Product Overview\n",
    "Product: \"Battlefield Conquerors\"\n",
    "Battlefield Conquerors is an immersive, action-packed First-Person Shooter (FPS) game that thrusts players into a gritty, fast-paced world of strategic warfare. Skill, precision, and quick thinking are the keys to victory in this adrenaline-fueled gaming experience.\n",
    "II. Sales Performance\n",
    "Battlefield Conquerors has achieved robust sales across multiple global regions, effectively penetrating the gaming market.\n",
    "North America (NA)\n",
    "In North America, the game has resonated particularly well, with a total of 1.5 million units sold. This success can be attributed to its strategic marketing campaign and the region's affinity for the FPS genre.\n",
    "Europe (EU)\n",
    "Europe has emerged as the game's most successful region in terms of sales, with an impressive 2.0 million units sold. The game's realistic graphics, dynamic gameplay, and stimulating storylines have been lauded by European gamers.\n",
    "Asia-Pacific (APAC)\n",
    "In the APAC region, Battlefield Conquerors has sold 1.0 million units. This solid performance is a testament to its broad appeal and the successful localization of the game's content for these markets.\n",
    "III. Financial Performance\n",
    "Battlefield Conquerors has not only met its financial targets but exceeded them. The game has achieved a performance of 1.2 times its initial budget, demonstrating its profitability and the successful return on investment.\n",
    "IV. Customer Feedback\n",
    "Customer feedback for Battlefield Conquerors has been overwhelmingly positive. Players have praised the game's innovative mechanics, immersive environment, and challenging gameplay.\n",
    "However, some concerns have been raised regarding the game's loading times. These issues have been acknowledged and are currently being addressed by the development team to ensure a seamless and uninterrupted gaming experience for all users moving forward.\n",
    "In conclusion, Battlefield Conquerors is a successful and profitable product, demonstrating strong sales performance across multiple regions. The few areas of improvement identified are being addressed to ensure continued success and customer satisfaction.\n",
    "\n",
    "Summary:\n",
    "Product Type:\n",
    "FPS\n",
    "\n",
    "Sales:\n",
    "NA: 1.5M\n",
    "EU: 2.0M\n",
    "APAC: 1.0M\n",
    "\n",
    "Performance:\n",
    "1.2 times budget.\n",
    "\n",
    "Feedback:\n",
    "Overall positive. Some concerns around loading times.\n",
    "END_EXAMPLE\n",
    "\n",
    "Document:\n",
    "{sales_report}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "result,prompt_tokens,completion_tokens,completion_text,e2e_time=aoai_call(system_message,prompt,model)\n",
    "print(f\"Prompt Tokens: {prompt_tokens}\")\n",
    "print(f\"Completion Tokens: {completion_tokens}\")\n",
    "print(f\"Time taken: {e2e_time:.2f} seconds\")\n",
    "print(completion_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case: Classification\n",
    "\n",
    "The imapact of this technique is proportionate to the number of documents being classified in series. There are other similar concepts that could be applied, by providing \"codes\" for the LLM to use to save time generating tokens.\n",
    "\n",
    "For more advanced techniques, see parallelization. These techniques can be combined for even greater speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_to_classify = \"\"\"[\n",
    "    \"Scientific research has led to significant advancements in medicine and healthcare.\",  \n",
    "    \"CLIP (Contrastive Language-Image Pretraining) - OpenAI's model that understands images in the context of natural language\",  \n",
    "    \"Science has contributed to our understanding of the natural world and the universe.\",  \n",
    "    \"Codex - OpenAI's AI system that can understand and generate code, powering GitHub Copilot\",  \n",
    "    \"GPT-4 - OpenAI's rumored next iteration of their language model with anticipated improvements\",  \n",
    "    \"Azure AI - Microsoft's suite of AI services, including machine learning, cognitive services, and conversational AI\",  \n",
    "     \"The collaboration and exchange of scientific knowledge across international borders have facilitated global progress in various fields.\" ,\n",
    "     \"Scientific innovations have improved communication and connectivity through technology.\", \n",
    "    \"Microsoft Turing Models - A series of large-scale language models developed by Microsoft\",  \n",
    "    \"Microsoft Project Brainwave - Real-time AI platform for cloud and edge computing\",  \n",
    "    \"Microsoft AI for Earth - A program applying AI to environmental challenges\",  \n",
    "    \"Microsoft AI for Health - An initiative leveraging AI for health-related research\",  \n",
    "    \"Scientific innovations have improved communication and connectivity through technology.\",  \n",
    "    \"OpenAI's API - Providing access to GPT-3 and other models for various applications\",   \n",
    "    \"Scientific research has led to significant advancements in medicine and healthcare.\",  \n",
    "    \"CLIP (Contrastive Language-Image Pretraining) - OpenAI's model that understands images in the context of natural language\",  \n",
    "    \"Science has contributed to our understanding of the natural world and the universe.\",  \n",
    "    \"Codex - OpenAI's AI system that can understand and generate code, powering GitHub Copilot\",  \n",
    "    \"GPT-4 - OpenAI's rumored next iteration of their language model with anticipated improvements\",  \n",
    "    \"Azure AI - Microsoft's suite of AI services, including machine learning, cognitive services, and conversational AI\",  \n",
    "     \"The collaboration and exchange of scientific knowledge across international borders have facilitated global progress in various fields.\" ,\n",
    "     \"Scientific innovations have improved communication and connectivity through technology.\", \n",
    "    \"Microsoft Turing Models - A series of large-scale language models developed by Microsoft\",  \n",
    "    \"Microsoft Project Brainwave - Real-time AI platform for cloud and edge computing\",  \n",
    "    \"Microsoft AI for Earth - A program applying AI to environmental challenges\",  \n",
    "    \"Microsoft AI for Health - An initiative leveraging AI for health-related research\",  \n",
    "    \"Scientific innovations have improved communication and connectivity through technology.\",  \n",
    "    \"OpenAI's API - Providing access to GPT-3 and other models for various applications\",   \n",
    "]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A: Classifying documents using the full category name\n",
    "\n",
    "**Time taken: 12.5 seconds**\n",
    "\n",
    "Here the model is providing the classification labels as the full text of the category name. This takes additional time, as more tokens are required per category name classified. The model has already made the determination of the class, but it takes additional time to convey that information to the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Tokens: 694\n",
      "Completion Tokens: 175\n",
      "Total cost: $0.0626\n",
      "Time taken: 12.58 seconds\n",
      "[SCIENCE, ARTIFICIAL INTELLIGENCE, SCIENCE, ARTIFICIAL INTELLIGENCE, ARTIFICIAL INTELLIGENCE, ARTIFICIAL INTELLIGENCE, SCIENCE, SCIENCE, ARTIFICIAL INTELLIGENCE, ARTIFICIAL INTELLIGENCE, ARTIFICIAL INTELLIGENCE, ARTIFICIAL INTELLIGENCE, SCIENCE, ARTIFICIAL INTELLIGENCE, SCIENCE, ARTIFICIAL INTELLIGENCE, SCIENCE, ARTIFICIAL INTELLIGENCE, ARTIFICIAL INTELLIGENCE, ARTIFICIAL INTELLIGENCE, SCIENCE, SCIENCE, ARTIFICIAL INTELLIGENCE, ARTIFICIAL INTELLIGENCE, ARTIFICIAL INTELLIGENCE, ARTIFICIAL INTELLIGENCE, SCIENCE, ARTIFICIAL INTELLIGENCE]\n"
     ]
    }
   ],
   "source": [
    "system_message=\"\"\"\n",
    "You are an helpful AI assistant that categorizes text in one of these categories : [A]: SCIENCE, [B]: ARTIFICIAL INTELLIGENCE, [C]: ART, [D]: HUMANITIES. \n",
    "Do not add any additional information.\n",
    "\n",
    "DOCUMENTS_TO_CLASSIFY:\n",
    "[\"GPT-3 (Generative Pre-trained Transformer 3) - OpenAI's powerful language model capable of writing like a human\",  \n",
    "\"Pigeons’ Backflips Linked to Genetics Scientists have unraveled the genetic basis behind a fascinating avian behavior\",\n",
    "]\n",
    "Example: [ARTIFICIAL INTELLIGENCE, SCIENCE]\n",
    "\"\"\"\n",
    "prompt=f\"\"\"\n",
    "DOCUMENTS_TO_CLASSIFY:\n",
    "{documents_to_classify}\n",
    "\"\"\"\n",
    "\n",
    "result,prompt_tokens,completion_tokens,completion_text,e2e_time=aoai_call(system_message,prompt,model)\n",
    "print(f\"Prompt Tokens: {prompt_tokens}\")\n",
    "print(f\"Completion Tokens: {completion_tokens}\")\n",
    "print(f\"Time taken: {e2e_time:.2f} seconds\")\n",
    "print(completion_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B: Use Categories to reduce the number of tokens generated\n",
    "\n",
    "**Time taken: 4 seconds**\n",
    "\n",
    "By assigning codes to each of the categories, the LLM only has to generate a single token per document classified. This is significantly faster. The codes can then be mapped back to the original class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Tokens: 712\n",
      "Completion Tokens: 84\n",
      "Time taken: 6.60 seconds\n",
      "[\"A\", \"B\", \"A\", \"B\", \"B\", \"B\", \"A\", \"A\", \"B\", \"B\", \"B\", \"B\", \"A\", \"B\", \"A\", \"B\", \"A\", \"B\", \"B\", \"B\", \"A\", \"A\", \"B\", \"B\", \"B\", \"B\", \"A\", \"B\"]\n"
     ]
    }
   ],
   "source": [
    "system_message=\"\"\"\n",
    "You are an helpful AI assistant that categorizes text in one of these categories : [A]: SCIENCE, [B]: ARTIFICIAL INTELLIGENCE, [C]: ART, [D]: HUMANITIES. \n",
    "Do not add any additional information. Only responde with the code for the category. For example, if it is SCIENCE, respond with [A].\n",
    "\n",
    "DOCUMENTS_TO_CLASSIFY:\n",
    "[\"GPT-3 (Generative Pre-trained Transformer 3) - OpenAI's powerful language model capable of writing like a human\",  \n",
    "\"Pigeons’ Backflips Linked to Genetics Scientists have unraveled the genetic basis behind a fascinating avian behavior\",\n",
    "]\n",
    "Example: [\"B\", \"A\"]\n",
    "\"\"\"\n",
    "prompt=f\"\"\"\n",
    "DOCUMENTS_TO_CLASSIFY:\n",
    "{documents_to_classify}\n",
    "\"\"\"\n",
    "\n",
    "result,prompt_tokens,completion_tokens,completion_text,e2e_time=aoai_call(system_message,prompt,model)\n",
    "print(f\"Prompt Tokens: {prompt_tokens}\")\n",
    "print(f\"Completion Tokens: {completion_tokens}\")\n",
    "print(f\"Time taken: {e2e_time:.2f} seconds\")\n",
    "print(completion_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SCIENCE', 'ARTIFICIAL INTELLIGENCE', 'SCIENCE', 'ARTIFICIAL INTELLIGENCE', 'ARTIFICIAL INTELLIGENCE', 'ARTIFICIAL INTELLIGENCE', 'SCIENCE', 'SCIENCE', 'ARTIFICIAL INTELLIGENCE', 'ARTIFICIAL INTELLIGENCE', 'ARTIFICIAL INTELLIGENCE', 'ARTIFICIAL INTELLIGENCE', 'SCIENCE', 'ARTIFICIAL INTELLIGENCE', 'SCIENCE', 'ARTIFICIAL INTELLIGENCE', 'SCIENCE', 'ARTIFICIAL INTELLIGENCE', 'ARTIFICIAL INTELLIGENCE', 'ARTIFICIAL INTELLIGENCE', 'SCIENCE', 'SCIENCE', 'ARTIFICIAL INTELLIGENCE', 'ARTIFICIAL INTELLIGENCE', 'ARTIFICIAL INTELLIGENCE', 'ARTIFICIAL INTELLIGENCE', 'SCIENCE', 'ARTIFICIAL INTELLIGENCE']\n"
     ]
    }
   ],
   "source": [
    "# Reformat to original categories\n",
    "\n",
    "# Replace single quotes with double quotes\n",
    "document_classes_list=json.loads(completion_text)\n",
    "\n",
    "# Define the dictionary\n",
    "categories = {'A': 'SCIENCE', 'B': 'ARTIFICIAL INTELLIGENCE', 'C': 'ART', 'D': 'HUMANITIES'}\n",
    "\n",
    "# Replace the letters with the categories\n",
    "lst = [categories[i] for i in document_classes_list]\n",
    "\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case: Generating structured data in lists instead of JSON\n",
    "\n",
    "Often JSON is used as an output format of an LLM. It provides keys which are clear as to what the value being output is, and easy to use in downstream steps.\n",
    "\n",
    "However, a significant number of tokens can end up being generated writing out the keys over and over. This takes a significant amount of time for the LLM.\n",
    "\n",
    "A list is a more efficient data structure, as it simply uses the order of the elements to preserve the meaning. The list can then be restructured into a JSON (or dictionary) using code, if desired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A: Base Case: Using JSON\n",
    "\n",
    "**Time taken: 66 seconds**\n",
    "\n",
    "This is the typical structure used in online guides, tutorials, and many production applications. An advantage is that the meaning of each value is clearer, and it can be easier to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Tokens: 153\n",
      "Completion Tokens: 860\n",
      "Time taken: 66.58 seconds\n",
      "[\n",
      "    {\n",
      "        \"make\": \"Toyota\",\n",
      "        \"model\": \"Camry\",\n",
      "        \"year\": 2020,\n",
      "        \"color\": \"Black\",\n",
      "        \"price\": 30000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Ford\",\n",
      "        \"model\": \"Focus\",\n",
      "        \"year\": 2019,\n",
      "        \"color\": \"White\",\n",
      "        \"price\": 20000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"BMW\",\n",
      "        \"model\": \"X5\",\n",
      "        \"year\": 2021,\n",
      "        \"color\": \"Blue\",\n",
      "        \"price\": 60000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Mercedes-Benz\",\n",
      "        \"model\": \"E-Class\",\n",
      "        \"year\": 2021,\n",
      "        \"color\": \"Silver\",\n",
      "        \"price\": 55000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Audi\",\n",
      "        \"model\": \"A5\",\n",
      "        \"year\": 2018,\n",
      "        \"color\": \"Red\",\n",
      "        \"price\": 40000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Honda\",\n",
      "        \"model\": \"Civic\",\n",
      "        \"year\": 2021,\n",
      "        \"color\": \"Grey\",\n",
      "        \"price\": 22000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Hyundai\",\n",
      "        \"model\": \"Elantra\",\n",
      "        \"year\": 2019,\n",
      "        \"color\": \"Black\",\n",
      "        \"price\": 18000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Tesla\",\n",
      "        \"model\": \"Model 3\",\n",
      "        \"year\": 2022,\n",
      "        \"color\": \"White\",\n",
      "        \"price\": 50000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Chevrolet\",\n",
      "        \"model\": \"Impala\",\n",
      "        \"year\": 2020,\n",
      "        \"color\": \"Blue\",\n",
      "        \"price\": 27000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Volkswagen\",\n",
      "        \"model\": \"Passat\",\n",
      "        \"year\": 2021,\n",
      "        \"color\": \"Green\",\n",
      "        \"price\": 25000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Subaru\",\n",
      "        \"model\": \"Outback\",\n",
      "        \"year\": 2022,\n",
      "        \"color\": \"Red\",\n",
      "        \"price\": 32000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Lexus\",\n",
      "        \"model\": \"RX\",\n",
      "        \"year\": 2021,\n",
      "        \"color\": \"White\",\n",
      "        \"price\": 45000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Jeep\",\n",
      "        \"model\": \"Grand Cherokee\",\n",
      "        \"year\": 2021,\n",
      "        \"color\": \"Black\",\n",
      "        \"price\": 40000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Porsche\",\n",
      "        \"model\": \"Cayenne\",\n",
      "        \"year\": 2022,\n",
      "        \"color\": \"Blue\",\n",
      "        \"price\": 75000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Dodge\",\n",
      "        \"model\": \"Charger\",\n",
      "        \"year\": 2020,\n",
      "        \"color\": \"Red\",\n",
      "        \"price\": 35000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Nissan\",\n",
      "        \"model\": \"Altima\",\n",
      "        \"year\": 2020,\n",
      "        \"color\": \"Grey\",\n",
      "        \"price\": 24000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Mazda\",\n",
      "        \"model\": \"3\",\n",
      "        \"year\": 2021,\n",
      "        \"color\": \"White\",\n",
      "        \"price\": 21000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Kia\",\n",
      "        \"model\": \"Forte\",\n",
      "        \"year\": 2021,\n",
      "        \"color\": \"Black\",\n",
      "        \"price\": 18000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"BMW\",\n",
      "        \"model\": \"328i\",\n",
      "        \"year\": 2019,\n",
      "        \"color\": \"Blue\",\n",
      "        \"price\": 41000\n",
      "    },\n",
      "    {\n",
      "        \"make\": \"Mercedes-Benz\",\n",
      "        \"model\": \"C-Class\",\n",
      "        \"year\": 2021,\n",
      "        \"color\": \"Silver\",\n",
      "        \"price\": 42000\n",
      "    }\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "system_message=\"\"\"\n",
    "You are an helpful AI assistant.\n",
    "\"\"\"\n",
    "prompt=f\"\"\"\n",
    "Generate 20 cars in a JSON format. Each car should have the following attributes: make, model, year, color, and price. The cars should be diverse in terms of make, model, and color.\n",
    "Example:\n",
    "[\n",
    "    {{\n",
    "        \"make\": \"Toyota\",\n",
    "        \"model\": \"Corolla\",\n",
    "        \"year\": 2022,\n",
    "        \"color\": \"blue\",\n",
    "        \"price\": 25000\n",
    "    }},\n",
    "    {{\n",
    "        \"make\": \"Ford\",\n",
    "        \"model\": \"Mustang\",\n",
    "        \"year\": 2021,\n",
    "        \"color\": \"red\",\n",
    "        \"price\": 35000\n",
    "    }},\n",
    "    ...\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "result,prompt_tokens,completion_tokens,completion_text,e2e_time=aoai_call(system_message,prompt,model)\n",
    "print(f\"Prompt Tokens: {prompt_tokens}\")\n",
    "print(f\"Completion Tokens: {completion_tokens}\")\n",
    "print(f\"Time taken: {e2e_time:.2f} seconds\")\n",
    "print(completion_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B: Using a list\n",
    "\n",
    "**Time taken: 28 seconds**\n",
    "\n",
    "Here the output is a list of lists, where each list contains the relevant parameters of the car in an expected order. This is significantly faster, as the LLM does not need to generate output tokens for each key in the dictionary.\n",
    "\n",
    "Once the task is completed, the list can be converted into a list programmatically, if so desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Tokens: 210\n",
      "Completion Tokens: 407\n",
      "Time taken: 25.36 seconds\n",
      "[\n",
      "    [\"Ford\", \"Mustang\", 2016, \"Red\", \"$20000\"],\n",
      "    [\"Chevrolet\", \"Camaro\", 2021, \"Blue\", \"$30000\"],\n",
      "    [\"Toyota\", \"Camry\", 2014, \"White\", \"$15000\"],\n",
      "    [\"BMW\", \"M4\", 2018, \"Black\", \"$45000\"],\n",
      "    [\"Audi\", \"A4\", 2020, \"Silver\", \"$40000\"],\n",
      "    [\"Porsche\", \"911\", 2019, \"Yellow\", \"$110000\"],\n",
      "    [\"Jaguar\", \"XF\", 2022, \"Black\", \"$60000\"],\n",
      "    [\"Honda\", \"Civic\", 2019, \"Grey\", \"$19000\"],\n",
      "    [\"Dodge\", \"Challenger\", 2020, \"Red\", \"$28000\"],\n",
      "    [\"Jeep\", \"Wrangler\", 2018, \"Green\", \"$35000\"],\n",
      "    [\"Maserati\", \"Ghibli\", 2021, \"Blue\", \"$70000\"],\n",
      "    [\"Rolls Royce\", \"Phantom\", 2020, \"White\", \"$450000\"],\n",
      "    [\"Mercedes-Benz\", \"C-class\", 2017, \"Black\", \"$35000\"],\n",
      "    [\"Hyundai\", \"Elantra\", 2019, \"Red\", \"$18000\"],\n",
      "    [\"Volkswagen\", \"Golf\", 2016, \"Blue\", \"$15000\"],\n",
      "    [\"Subaru\", \"Impreza\", 2020, \"Silver\", \"$22000\"],\n",
      "    [\"Tesla\", \"Model 3\", 2021, \"White\", \"$39000\"],\n",
      "    [\"Lexus\", \"ES\", 2018, \"Grey\", \"$28000\"],\n",
      "    [\"Nissan\", \"Altima\", 2019, \"Black\", \"$24000\"],\n",
      "    [\"Kia\", \"Sorento\", 2020, \"Blue\", \"$32000\"]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "system_message=\"\"\"\n",
    "You are an helpful AI assistant.\n",
    "\"\"\"\n",
    "prompt=f\"\"\"\n",
    "Generate 20 cars in a list. Each car should have the following attributes: make, model, year, color, and price. The cars should be diverse in terms of make, model, and color. Output only exactly the list of cars, no additional text or comments.\n",
    "Example:\n",
    "[\n",
    "    [\n",
    "        \"the first element is the make of the car\",\n",
    "        \"the second element is the model of the car\",\n",
    "        \"the third element is the year of the car\",\n",
    "        \"the fourth element is the color of the car\",\n",
    "        \"the fifth element is the price of the car\"\n",
    "    ],\n",
    "    [\n",
    "        \"the first element is the make of the car\",\n",
    "        \"the second element is the model of the car\",\n",
    "        \"the third element is the year of the car\",\n",
    "        \"the fourth element is the color of the car\",\n",
    "        \"the fifth element is the price of the car\"\n",
    "    ],\n",
    "    ...\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "result,prompt_tokens,completion_tokens,completion_text,e2e_time=aoai_call(system_message,prompt,model)\n",
    "print(f\"Prompt Tokens: {prompt_tokens}\")\n",
    "print(f\"Completion Tokens: {completion_tokens}\")\n",
    "print(f\"Time taken: {e2e_time:.2f} seconds\")\n",
    "print(completion_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'make': 'A'}, {'make': 'B'}, {'make': 'A'}, {'make': 'B'}, {'make': 'B'}, {'make': 'B'}, {'make': 'A'}, {'make': 'A'}, {'make': 'B'}, {'make': 'B'}, {'make': 'B'}, {'make': 'B'}, {'make': 'A'}, {'make': 'B'}, {'make': 'A'}, {'make': 'B'}, {'make': 'A'}, {'make': 'B'}, {'make': 'B'}, {'make': 'B'}, {'make': 'A'}, {'make': 'A'}, {'make': 'B'}, {'make': 'B'}, {'make': 'B'}, {'make': 'B'}, {'make': 'A'}, {'make': 'B'}]\n"
     ]
    }
   ],
   "source": [
    "# Programatically turn the list back into a dict (JSON)\n",
    "\n",
    "car_list=json.loads(completion_text)\n",
    "\n",
    "# Define the keys for the dictionaries\n",
    "keys = [\"make\", \"model\", \"year\", \"color\", \"price\"]\n",
    "\n",
    "# Convert the list of lists into a list of dictionaries\n",
    "dict_list = [dict(zip(keys, sublist)) for sublist in car_list]\n",
    "\n",
    "print(dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
