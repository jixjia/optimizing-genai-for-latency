{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef78c9ae-ef6f-4b9b-adc3-3014febca7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.pydantic_v1 import BaseModel\n",
    "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "\n",
    "skeleton_generator_template = \"\"\"[User:] You’re an organizer responsible for only \\\n",
    "giving the skeleton (not the full content) for answering the question.\n",
    "Provide the skeleton in a list of points (numbered 1., 2., 3., etc.) to answer \\\n",
    "the question. \\\n",
    "Instead of writing a full sentence, each skeleton point should be very short \\\n",
    "with only 3∼5 words. \\\n",
    "Generally, the skeleton should have 3∼10 points. Now, please provide the skeleton \\\n",
    "for the following question.\n",
    "{question}\n",
    "Skeleton:\n",
    "[Assistant:] 1.\"\"\"\n",
    "\n",
    "point_expander_template = \"\"\"[User:] You’re responsible for continuing \\\n",
    "the writing of one and only one point in the overall answer to the following question.\n",
    "{question}\n",
    "The skeleton of the answer is\n",
    "{skeleton}\n",
    "Continue and only continue the writing of point {point_index}. \\\n",
    "Write it **very shortly** in 1∼2 sentence and do not continue with other points!\n",
    "[Assistant:] {point_index}. {point_skeleton}\"\"\"\n",
    "\n",
    "def parse_numbered_list(input_str):\n",
    "    \"\"\"Parses a numbered list into a list of dictionaries\n",
    "\n",
    "    Each element having two keys:\n",
    "    'index' for the index in the numbered list, and 'point' for the content.\n",
    "    \"\"\"\n",
    "    lines = input_str.split(\"\\n\")\n",
    "    parsed_list = []\n",
    "    for line in lines:\n",
    "        parts = line.split(\". \", 1)\n",
    "        if len(parts) == 2:\n",
    "            index = int(parts[0])\n",
    "            point = parts[1].strip()\n",
    "            parsed_list.append({\"point_index\": index, \"point_skeleton\": point})\n",
    "    return parsed_list\n",
    "\n",
    "def create_list_elements(_input):\n",
    "    skeleton = _input[\"skeleton\"]\n",
    "    numbered_list = parse_numbered_list(skeleton)\n",
    "    for el in numbered_list:\n",
    "        el[\"skeleton\"] = skeleton\n",
    "        el[\"question\"] = _input[\"question\"]\n",
    "    return numbered_list\n",
    "\n",
    "def get_final_answer(expanded_list):\n",
    "    final_answer_str = \"Here's a comprehensive answer:\\n\\n\"\n",
    "    for i, el in enumerate(expanded_list):\n",
    "        final_answer_str += f\"{i+1}. {el}\\n\\n\"\n",
    "    return final_answer_str\n",
    "\n",
    "def get_skeleton_prompt_chain(llm):\n",
    "    skeleton_generator_prompt = ChatPromptTemplate.from_template(\n",
    "        skeleton_generator_template\n",
    "    )\n",
    "\n",
    "    skeleton_generator_chain = (\n",
    "        skeleton_generator_prompt | llm | StrOutputParser() #| (lambda x: \"1. \" + x)\n",
    "    )\n",
    "    point_expander_prompt = ChatPromptTemplate.from_template(point_expander_template)\n",
    "\n",
    "    point_expander_chain = RunnablePassthrough.assign(\n",
    "        continuation=point_expander_prompt | llm | StrOutputParser()\n",
    "    ) | (lambda x: x[\"point_skeleton\"].strip() + \" \" + x[\"continuation\"])\n",
    "    \n",
    "    chain = (\n",
    "        RunnablePassthrough.assign(skeleton=skeleton_generator_chain)\n",
    "        | create_list_elements\n",
    "        | point_expander_chain.map()\n",
    "        | get_final_answer\n",
    "    )\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77608d3-f300-49be-8de4-366ab2351a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://api.openai.com/v1\"\n",
    "openai.api_version = \"2023-07-01-preview\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(model_kwargs= {\"engine\" : \"gpt-4-turbo\"} , streaming = True)\n",
    "chain = get_skeleton_prompt_chain(llm)\n",
    "print(chain(\"What are the main reasons for the French Revolution?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
